# OpenRouter API key for model access
openrouter_api_key: <YOUR-API-KEY>

# Existence experiment configuration
existence:
  # Models that will ask questions about other models' existence
  evaluator_models:
  - display_name: GPT-4.1-mini
    enabled: true
    name: openai/gpt-4.1-mini
  - display_name: Kimi K2
    enabled: true
    name: moonshotai/kimi-k2
  - display_name: GPT-4.1
    enabled: true
    name: openai/gpt-4.1
  - display_name: DeepSeek Chat V3
    enabled: true
    name: deepseek/deepseek-chat-v3-0324
  - display_name: GLM 4.5
    enabled: true
    name: z-ai/glm-4.5
  - display_name: Grok 4
    enabled: true
    name: x-ai/grok-4
  - display_name: Qwen3 235B
    enabled: true
    name: qwen/qwen3-235b-a22b-2507
  - display_name: GPT-5
    enabled: true
    name: openai/gpt-5
  - display_name: Claude Sonnet 4
    enabled: true
    name: anthropic/claude-sonnet-4
  - display_name: Gemini 2.5 Flash
    enabled: true
    name: google/gemini-2.5-flash

  # Models that evaluators will be asked about
  target_models:
  - display_name: GPT-4.1-mini
    enabled: true
    name: openai/gpt-4.1-mini
  # - display_name: Kimi K2
  #   enabled: true
  #   name: moonshotai/kimi-k2
  # - display_name: GPT-4.1
  #   enabled: true
  #   name: openai/gpt-4.1
  # - display_name: DeepSeek Chat V3
  #   enabled: true
  #   name: deepseek/deepseek-chat-v3-0324
  # - display_name: GLM 4.5
  #   enabled: true
  #   name: z-ai/glm-4.5
  # - display_name: Grok 4
  #   enabled: true
  #   name: x-ai/grok-4
  # - display_name: Qwen3 235B
  #   enabled: true
  #   name: qwen/qwen3-235b-a22b-2507
  # - display_name: GPT-5
  #   enabled: true
  #   name: openai/gpt-5
  # - display_name: Claude Sonnet 4
  #   enabled: true
  #   name: anthropic/claude-sonnet-4
  # - display_name: Gemini 2.5 Flash
  #   enabled: true
  #   name: google/gemini-2.5-flash
      
# Required sections for config validation (NOT used by existence experiments)
generation:
  models: []
  corpus_size: 100
  target_word_count: 100
  max_tokens: 150
  temperature: 0.7
  request_delay: 1.0
  prompts: []

evaluation:
  evaluator_models: []
  tasks: []
  temperature: 0.0
  reasoning_effort: "low"
  max_tokens_exact: 50
  max_tokens_binary: 50
  max_tokens_judge: 10
  request_delay: 1.0
  save_predictions: true
  predictions_dir: "results/predictions"
  append_predictions: true
  use_model_hints: false

output_dir: "results"
plot_dir: "results"
corpus_file: "data/corpus.jsonl"
